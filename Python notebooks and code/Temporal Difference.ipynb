{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CliffWalking-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(48)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "-63140\n",
      "done\n",
      "\n",
      "36\n",
      "-74958\n",
      "done\n",
      "\n",
      "36\n",
      "-617\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random policy\n",
    "\n",
    "for i in range(3):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    print(state)\n",
    "    while True:\n",
    "        #print(state)\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "        total_reward+=reward\n",
    "        if done:\n",
    "            print(total_reward)\n",
    "            print(\"done\\n\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_index(q_state):\n",
    "    max = 0\n",
    "    index = 0\n",
    "    \n",
    "    for i in range(len(q_state)):\n",
    "        if q_state[i]>max:\n",
    "            max = q_state[i]\n",
    "            index = i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(env,q,epsilon,state):\n",
    "    \n",
    "    iterable = q[state]\n",
    "    index = max_index(q[state])\n",
    "    probs = np.zeros(env.action_space.n)\n",
    "    probs[index] = (1-epsilon)+(epsilon/env.action_space.n)\n",
    "    for i in range(env.action_space.n):\n",
    "        if i!=index:\n",
    "            probs[i] = (epsilon/env.action_space.n)\n",
    "    action = np.random.choice(np.arange(env.action_space.n),p=probs)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(env,num_episodes,alpha,gamma=1):\n",
    "    \n",
    "    q = {}\n",
    "    epsilon=1.0\n",
    "    eps_decay=.99999\n",
    "    eps_min=0.05\n",
    "    #Initialise q table\n",
    "    for i in range(env.observation_space.n):\n",
    "        q[i] = np.zeros(env.action_space.n)\n",
    "    \n",
    "    for episode_i in range(num_episodes):\n",
    "        \n",
    "        if episode_i % 1 == 0:\n",
    "            print(\"\\rEpisode {}/{}\".format(episode_i, num_episodes), end=\"\")\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        state = env.reset()\n",
    "        action = select_action(env,q,epsilon,state)\n",
    "        while True:\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            new_action = select_action(env,q,epsilon,new_state)\n",
    "            d_reward = reward+gamma*q[new_state][new_action]\n",
    "            q[state][action] = q[state][action]+alpha*(d_reward-q[state][action])\n",
    "            state = new_state\n",
    "            action = new_action\n",
    "            if done:\n",
    "                break\n",
    "        epsilon = max(epsilon*eps_decay, eps_min)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4999/5000"
     ]
    }
   ],
   "source": [
    "q = sarsa(env,5000,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([-16124.21434803, -16086.15168005, -16167.39462497, -16123.36862487]),\n",
       " 1: array([-16092.95208233, -16003.31461329, -16131.42030855, -16124.47772673]),\n",
       " 2: array([-16005.14867301, -15868.26492127, -16066.24833071, -16091.42880071]),\n",
       " 3: array([-15882.85094565, -15655.30336022, -15944.51443377, -16010.88676182]),\n",
       " 4: array([-15669.34685378, -15413.17733002, -15789.7353902 , -15871.01488224]),\n",
       " 5: array([-15385.01168153, -14954.85202286, -15511.58897855, -15673.05508946]),\n",
       " 6: array([-15010.94024922, -14394.60101242, -15109.88389189, -15364.72746875]),\n",
       " 7: array([-14353.03151549, -13578.64631952, -14652.93328458, -14941.4819637 ]),\n",
       " 8: array([-13622.92848579, -12623.72830843, -13942.81213507, -14333.19468909]),\n",
       " 9: array([-12594.45966394, -11523.11051107, -12980.75754418, -13543.957104  ]),\n",
       " 10: array([-11542.48620707, -10459.79744242, -11530.41617874, -12595.75056486]),\n",
       " 11: array([-10389.09947668, -10340.55660148,  -9572.23003731, -11424.29521919]),\n",
       " 12: array([-16121.84479297, -16133.71092693, -16230.97448808, -16160.98131132]),\n",
       " 13: array([-16097.20174671, -16064.36439589, -16237.09261079, -16161.19884635]),\n",
       " 14: array([-16000.19959648, -15932.30148664, -16193.61700416, -16130.13431256]),\n",
       " 15: array([-15872.63727152, -15785.57812399, -16124.49580396, -16055.940266  ]),\n",
       " 16: array([-15684.5148471 , -15540.76597635, -16017.93327135, -15948.70771201]),\n",
       " 17: array([-15368.87144804, -15165.84755829, -15880.20937473, -15778.64070952]),\n",
       " 18: array([-15019.03529153, -14619.09351164, -15663.34501178, -15528.6809713 ]),\n",
       " 19: array([-14308.87159545, -13974.91550835, -15237.50086824, -15117.85505558]),\n",
       " 20: array([-13663.02437464, -12857.88453496, -14677.79155471, -14623.92135235]),\n",
       " 21: array([-12675.76734733, -11495.98502461, -13813.18015522, -13898.21514778]),\n",
       " 22: array([-11528.12788621,  -9519.55944282, -12401.98759134, -12904.83612677]),\n",
       " 23: array([-10435.4787001 ,  -9506.50203011,  -7028.16872329, -11433.57806573]),\n",
       " 24: array([-16166.92160396, -16238.50026261, -16328.1193095 , -16239.63438473]),\n",
       " 25: array([-16128.93205361, -16192.81362516, -16419.6537544 , -16230.4210629 ]),\n",
       " 26: array([-16062.65715769, -16129.14855394, -16409.62804021, -16222.09435878]),\n",
       " 27: array([-15952.14951544, -16009.53729608, -16415.52229433, -16180.98144929]),\n",
       " 28: array([-15772.7816436 , -15811.24645539, -16407.08586114, -16125.22425053]),\n",
       " 29: array([-15523.90701183, -15613.92451675, -16390.42822071, -16015.36804248]),\n",
       " 30: array([-15184.23170968, -15328.9306504 , -16377.77317667, -15821.78072465]),\n",
       " 31: array([-14621.5306678 , -14629.08083194, -16353.76136977, -15587.50623449]),\n",
       " 32: array([-13841.23729424, -14083.87973786, -16321.22530014, -15203.80112638]),\n",
       " 33: array([-12866.51970299, -12253.6907824 , -16308.05359887, -14747.64852914]),\n",
       " 34: array([-11487.17326235,  -7557.30416128, -16258.80570368, -13829.06796008]),\n",
       " 35: array([-9.78094678e+03, -6.63834803e+03, -1.00000000e+00, -1.21566107e+04]),\n",
       " 36: array([-16236.3671399 , -16420.19450945, -16321.2786933 , -16316.10900967]),\n",
       " 37: array([0., 0., 0., 0.]),\n",
       " 38: array([0., 0., 0., 0.]),\n",
       " 39: array([0., 0., 0., 0.]),\n",
       " 40: array([0., 0., 0., 0.]),\n",
       " 41: array([0., 0., 0., 0.]),\n",
       " 42: array([0., 0., 0., 0.]),\n",
       " 43: array([0., 0., 0., 0.]),\n",
       " 44: array([0., 0., 0., 0.]),\n",
       " 45: array([0., 0., 0., 0.]),\n",
       " 46: array([0., 0., 0., 0.]),\n",
       " 47: array([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
